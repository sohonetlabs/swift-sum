#!/usr/bin/env python -u

"""
swiftsum: calculates the checksum of the object including SLO and DLO segments

"""

import argparse
import hashlib
import os
import math

DEFAULT_SEGMENT_SIZE = '500M'
DEFAULT_READ_SIZE = '40Mi'

SYMBOLS = {
    'customary': ('B', 'K', 'M', 'G', 'T', 'P', 'E', 'Z', 'Y'),
    'customary_ext': ('byte', 'kilo', 'mega', 'giga', 'tera', 'peta', 'exa',
                      'zetta', 'iotta'),
    'iec': ('Bi', 'Ki', 'Mi', 'Gi', 'Ti', 'Pi', 'Ei', 'Zi', 'Yi'),
    'iec_ext': ('byte', 'kibi', 'mebi', 'gibi', 'tebi', 'pebi', 'exbi',
                'zebi', 'yobi'),
}


def human2bytes(s):
    """
    based on http://code.activestate.com/recipes/
        578019-bytes-to-human-human-to-bytes-converter/
    Attempts to guess the string format based on default symbols
    set and return the corresponding bytes as an integer.
    When unable to recognize the format ValueError is raised.

      >>> human2bytes('0 B')
      0
      >>> human2bytes('1 K')
      1024
      >>> human2bytes('1 M')
      1048576
      >>> human2bytes('1 Gi')
      1073741824
      >>> human2bytes('1 tera')
      1099511627776

      >>> human2bytes('0.5kilo')
      512
      >>> human2bytes('0.1  byte')
      0
      >>> human2bytes('1 k')  # k is an alias for K
      1024
      >>> human2bytes('12 foo')
      Traceback (most recent call last):
          ...
      ValueError: can't interpret '12 foo'
    """
    init = s
    num = ""
    while s and s[0:1].isdigit() or s[0:1] == '.':
        num += s[0]
        s = s[1:]
    num = float(num)
    letter = s.strip()
    for name, sset in SYMBOLS.items():
        if letter in sset:
            break
    else:
        if letter == 'k':
            # treat 'k' as an alias for 'K' as per: http://goo.gl/kTQMs
            sset = SYMBOLS['customary']
            letter = letter.upper()
        else:
            raise ValueError("can't interpret %r" % init)
    prefix = {sset[0]: 1}
    for i, s in enumerate(sset[1:]):
        prefix[s] = 1 << (i + 1) * 10
    return int(num * prefix[letter])


def bytes2human(n, format='%(value).1f %(symbol)s', symbols='customary'):
    """
    Convert n bytes into a human readable string based on format.
    symbols can be either "customary", "customary_ext", "iec" or "iec_ext",
    see: http://goo.gl/kTQMs

      >>> bytes2human(0)
      '0.0 B'
      >>> bytes2human(0.9)
      '0.0 B'
      >>> bytes2human(1)
      '1.0 B'
      >>> bytes2human(1.9)
      '1.0 B'
      >>> bytes2human(1024)
      '1.0 K'
      >>> bytes2human(1048576)
      '1.0 M'
      >>> bytes2human(1099511627776127398123789121)
      '909.5 Y'

      >>> bytes2human(9856, symbols="customary")
      '9.6 K'
      >>> bytes2human(9856, symbols="customary_ext")
      '9.6 kilo'
      >>> bytes2human(9856, symbols="iec")
      '9.6 Ki'
      >>> bytes2human(9856, symbols="iec_ext")
      '9.6 kibi'

      >>> bytes2human(10000, "%(value).1f %(symbol)s/sec")
      '9.8 K/sec'

      >>> # precision can be adjusted by playing with %f operator
      >>> bytes2human(10000, format="%(value).5f %(symbol)s")
      '9.76562 K'
    """
    n = int(n)
    if n < 0:
        raise ValueError("n < 0")
    symbols = SYMBOLS[symbols]
    prefix = {}
    for i, s in enumerate(symbols[1:]):
        prefix[s] = 1 << (i+1)*10
    for symbol in reversed(symbols[1:]):
        if n >= prefix[symbol]:
            value = float(n) / prefix[symbol]
            return format % locals()
    return format % dict(symbol=symbols[0], value=n)


def md5_for_file(f):
    _hash = hashlib.md5()
    while True:
        data = f.read(10240)
        if len(data) == 0:
            break
        _hash.update(data)
    return _hash.hexdigest()


def read_in_chunks(file_object, start=0, end=None, chunk_size=10240):
    """
    Read a file f in chunks of size 'chunk_size' from start to end
    """
    f.seek(start)
    if not end:
        stat_info = os.stat(file_object)
        end = stat_info.st_size
    current_position = start
    while current_position < end:
        current_chunk_size = chunk_size
        if current_position + chunk_size > end:
            current_chunk_size = (end - current_position)
        _data = file_object.read(current_chunk_size)
        if not _data:
            break
        yield _data
        current_position += current_chunk_size


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description='Calculates the checksum of the object including '
                    'SLO and DLO segments.')
    parser.add_argument('-s', '--segmentsize', dest='segment_size',
                        default=DEFAULT_SEGMENT_SIZE,
                        help='File segment size (default: %s)'
                             % DEFAULT_SEGMENT_SIZE)
    parser.add_argument('-r', '--readsize', dest='read_size',
                        default=DEFAULT_READ_SIZE,
                        help='Segment size to read from disk (default: %s)'
                             % DEFAULT_READ_SIZE)
    parser.add_argument('--slo', default=True,
                        help='Calculate the SLO (Static Large Object) '
                             'checksum (default).',
                        action='store_true')
    parser.add_argument('--dlo', default=False,
                        help='Calculate the DLO (Dynamic Large Object) '
                             'checksum.',
                        action='store_true')
    parser.add_argument('-v', '--verbose', default=False,
                        help='Verbose (default: off).',
                        action='store_true')
    parser.add_argument('filename', nargs='+', help='file name to check')
    args = parser.parse_args()

    segment_size = human2bytes(args.segment_size)
    read_size = human2bytes(args.read_size)
    filenames = args.filename
    verbose = args.verbose

    for filename in filenames:
        try:
            f = open(filename, 'rb')
            filesize = os.path.getsize(filename)

        except IOError:
            print 'Could not open %s' % filename
        else:
            if filesize > segment_size:
                # calc the md5's for the segments
                segment_md5s = []
                segments_to_read = []
                num_chunks = int(math.ceil(filesize / float(segment_size)))
                file_hash = hashlib.md5()
                slo_md5 = hashlib.md5()
                # work out the chunks to read
                for chunk in range(0, num_chunks):
                    segments_to_read.append(
                        (chunk * segment_size,
                         chunk * segment_size + segment_size))

                for (chunk_start, chunk_end) in segments_to_read:
                    # calc the md5 for each chunk
                    # also calc the hash of the file for sanity check
                    chunk_md5 = hashlib.md5()
                    for chunk in read_in_chunks(f, start=chunk_start,
                                                end=chunk_end):
                        chunk_md5.update(chunk)
                        file_hash.update(chunk)
                    if verbose:
                        print "MD5 for %s-%s %s: %s " % (chunk_start,
                                                         chunk_end, filename,
                                                         chunk_md5.hexdigest())
                    segment_md5s.append(chunk_md5.hexdigest())
                    slo_md5.update(chunk_md5.hexdigest())

                print 'MD5 for %s: %s' % (filename,  file_hash.hexdigest())
                print 'SLO TAG for %s: %s' % (filename, slo_md5.hexdigest())
            else:
                # calc the md5 checksum for the whole file
                print "MD5 For %s: %s " % (filename, md5_for_file(f))
        finally:
            f.close()
